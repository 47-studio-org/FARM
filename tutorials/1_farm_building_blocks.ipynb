{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FARM Building Blocks\n",
    "\n",
    "Welcome to the FARM building blocks tutorial! There are many different ways to make use of this repository, but in this notebook, we will be going through the most import building blocks that will help you harvest the rewards of a successfully trained NLP model.\n",
    "\n",
    "Happy FARMing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Text Classification\n",
    "\n",
    "GNAD (https://tblock.github.io/10kGNAD/) is a dataset of 10K German documents labelled with one of 9 classes. In this section, we are going to build a classifier for this task that is composed of Google's BERT language model and a feed forward neural network prediction head."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory is /Users/deepset/deepset/FARM\n"
     ]
    }
   ],
   "source": [
    "# Let's start by adjust the working directory so that it is the root of the repository\n",
    "# This should be run just once.\n",
    "\n",
    "import os\n",
    "os.chdir('../')\n",
    "print(\"Current working directory is {}\".format(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Apex not installed. If you use distributed training with local rank != -1 apex must be installed.\n"
     ]
    }
   ],
   "source": [
    "# Here are the imports we need\n",
    "\n",
    "import torch\n",
    "from farm.modeling.tokenization import BertTokenizer\n",
    "from farm.data_handler.processor import GNADProcessor\n",
    "from farm.data_handler.data_silo import DataSilo\n",
    "from farm.modeling.language_model import Bert\n",
    "from farm.modeling.prediction_head import TextClassificationHead\n",
    "from farm.modeling.adaptive_model import AdaptiveModel\n",
    "from farm.experiment import initialize_optimizer\n",
    "from farm.train import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Devices available: cpu\n"
     ]
    }
   ],
   "source": [
    "# We need to fetch the right device to drive the growth of our model\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Devices available: {}\".format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/24/2019 14:37:05 - INFO - farm.modeling.tokenization_utils -   loading file https://int-deepset-models-bert.s3.eu-central-1.amazonaws.com/pytorch/bert-base-german-cased-vocab.txt from cache at /Users/deepset/.cache/torch/farm/da299cdd121a3d71e1626f2908dda0d02658f42e925a3d6abd8273ec08cf41a6.2a48e6c60dcdb582effb718237ce5894652e3b4abb94f0a4d9a857b70333308d\n"
     ]
    }
   ],
   "source": [
    "# Here we initialize a tokenizer that will be used for preprocessing text\n",
    "# This is the BERT Tokenizer which uses the byte pair encoding method.\n",
    "# It is currently loaded with a German model\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"bert-base-german-cased\",\n",
    "    do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Selbst',\n",
       " 'ein',\n",
       " 'bl',\n",
       " '##inde',\n",
       " '##s',\n",
       " 'Hu',\n",
       " '##hn',\n",
       " 'findet',\n",
       " 'mal',\n",
       " 'ein',\n",
       " 'Korn',\n",
       " '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can test out how it will do on an example sentence\n",
    "\n",
    "EXAMPLE_SENTENCE = \"Selbst ein blindes Huhn findet mal ein Korn.\"\n",
    "tokenizer.tokenize(EXAMPLE_SENTENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to prepare the data for the model, we need a set of\n",
    "# functions to transform data files into PyTorch Datasets.\n",
    "# We group these together in Processor objects.\n",
    "# We will need a new Processor object for each new source of data.\n",
    "# The abstract class can be found in farm.data_handling.processor.Processor\n",
    "\n",
    "processor = GNADProcessor(tokenizer=tokenizer,\n",
    "                          max_seq_len=128,\n",
    "                          data_dir=\"data/gnad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/24/2019 14:37:14 - INFO - farm.data_handler.data_silo -   Loading train set from: data/gnad/train.csv\n",
      "07/24/2019 14:37:14 - INFO - farm.data_handler.utils -   downloading and extracting file gnad to dir /Users/deepset/deepset/FARM/data\n",
      "100%|██████████| 10753295/10753295 [00:28<00:00, 377680.96B/s]\n",
      "07/24/2019 14:40:52 - INFO - farm.data_handler.processor -   *** Show 3 random examples ***\n",
      "07/24/2019 14:40:52 - INFO - farm.data_handler.processor -   *** Example ***\n",
      "ID: train-7025-0\n",
      "Clear Text: \n",
      " \tlabel: Wissenschaft\n",
      " \ttext: Das Zentrum für Soziale Innovation ist beteiligt an EU-Projekt für mehr Verantwortung in der Wissenschaft. Wien - Im Verhältnis von Wissenschaft und Gesellschaft lässt sich eine Doppelbewegung ausmachen: Einerseits rücken durch die Technisierung zunehmend Artefakte der Wissenschaft in die Lebenswelt, andererseits werden Forschung und die daraus resultierenden Anwendungen immer spezialisierter und entziehen sich so zunehmend dem Verständnis der meisten. Angesichts der starken Veränderungen der Lebenswelt durch den wissenschaftlichen Fortschritt hat die Europäische Kommission daher eine Initiative gestartet, die Wissenschaft und Gesellschaft wieder näher zusammenrücken lassen sollen. Federführend dabei ist ein Konzept, das Responsible Research and Innovation (RRI) genannt wird. 26 Institutionen sind europaweit an dem von der EU geförderten RRI Tools-Projekt beteiligt, bei dem es darum geht, sowohl Wissenschaftern als auch politischen Entscheidungsträgern, Wirtschaftstreibenden und der breiten Bevölkerung Tools zur Verfügung zu stellen, die letztlich zu einer nachhaltigen Forschung beitragen sollen. Das Vokabular ist dabei nicht unumstritten: So mutet es etwas technokratisch an, von Werkzeugen zu sprechen, wo es darum geht, neue Praktiken zu entwickeln und einen Sinneswandel und Selbstreflexion herbeizuführen. Auch gebe es Kritik, dass das Konzept irgendwo einmal ausgedacht worden ist, aber ihm noch die Bodenhaftung und die praktische Umsetzung fehlt, sagt die Soziologin Ilse Marschalekvom Zentrum für Soziale Innovation (ZSI), die in Österreich für die Koordination zuständig ist. Gemeinsame Verantwortung Wenn Wissenschafter mit RRI konfrontiert werden, komme es nicht selten vor, dass sie sich zunächst angegriffen fühlen und fragen: Waren wir bis jetzt nicht verantwortungsvoll genug?, berichtetMarschalek, das ist aber natürlich nicht gemeint, sondern es geht darum, dass die Verantwortung von allen gleichermaßen getragen wird - von Wissenschaftern, Policy Makers und der Wirtschaft. Nachdem in den letzten eineinhalb Jahren zahlreiche Gespräche und Workshops mit verschiedenen Akteuren stattfanden, geht es im nächsten Schritt um die Entwicklung von Werkzeugen - mit dem Ziel, RRI durchzusetzen. Wie diese genau aussehen werden, sei noch unklar. Denkbar wären etwa Trainingsmaterialien, Kurzvideos, Poster oder Powerpoint-Präsentationen, mit denen das Konzept von RRI vermittelt werden kann und Handlungsanleitungen gegeben werden können, die eigenen Aktivitäten hinsichtlich RRI zu beurteilen. Letztlich geht es um eine nachhaltige Forschung, um einen Paradigmenwechsel in der Wissenschaft, sagt Marschalek, eine Bewegung hinaus aus dem Elfenbeinturm, hin zu Science with and for society. Dabei sei nicht nur ein Einstellungswandel unter den Forschern erforderlich, sondern es gehe auch darum, die Forschungsförderung zu überdenken, sagt Katharina Handler, die am ZSI ebenfalls am Projekt beteiligt ist. Es müsse reflektiert werden, wie viel Geld wofür ausgegeben wird und welchen Gesellschaftsgruppen das nützlich ist. Mit den neuen technischen Möglichkeiten müssen wir auch einen neuen Ansatz in der Reflexion finden, wie diese Technologien von allen akzeptiert werden können, sagt Marschalek. Warum es gerade jetzt ein gesteigertes Verantwortungsbewusstsein der Wissenschaft brauche, begründet Marschalek mit den veränderten technischen Möglichkeiten: Mit Nanotechnologie bis hin zu Gentechnik verschiebe sich die Grenze, wozu Forschung imstande ist. Wissenschaft und Technik infiltriert unser Leben immer mehr. Ganz selbstverständlich kommen wir jeden Tag mit Hightech in Berührung. Dementsprechend haben die Leute mehr Interesse und mehr Möglichkeiten, sich zu interessieren und sich zu engagieren, sagt Marschalek. Neue Initiative Eine ähnliche Stoßrichtung wie das RRI Tool-Projekt verfolgt die Initiative Responsible Science - Wissenschaft und Gesellschaft im Dialog des Wissenschaftsministeriums. Im Sinne einer nachhaltigen Innovationsorientierung soll damit das Interesse der Gesellschaft an Wissenschaft und Forschung gestärkt werden - mit dem Langzeitziel, die überdurchschnittlich wissenschaftsskeptischen Österreicher näher an die Forschung heranzuführen, um sie so dafür zu begeistern.\n",
      "Tokenized: \n",
      " \t tokens: ['Das', 'Zentrum', 'für', 'Sozial', '##e', 'Innovation', 'ist', 'beteiligt', 'an', 'EU', '-', 'Projekt', 'für', 'mehr', 'Verantwortung', 'in', 'der', 'Wissenschaft', '.', 'Wien', '-', 'Im', 'Verhältnis', 'von', 'Wissenschaft', 'und', 'Gesellschaft', 'lässt', 'sich', 'eine', 'Doppel', '##bewegung', 'aus', '##machen', ':', 'Einer', '##seits', 'rück', '##en', 'durch', 'die', 'Techn', '##isierung', 'zunehmend', 'Arte', '##fa', '##kte', 'der', 'Wissenschaft', 'in', 'die', 'Lebens', '##welt', ',', 'andererseits', 'werden', 'Forschung', 'und', 'die', 'daraus', 'result', '##ierenden', 'Anwendungen', 'immer', 'spezialisierte', '##r', 'und', 'entziehen', 'sich', 'so', 'zunehmend', 'dem', 'Verständnis', 'der', 'meisten', '.', 'Angesichts', 'der', 'starken', 'Veränderungen', 'der', 'Lebens', '##welt', 'durch', 'den', 'wissenschaft', '##lichen', 'Fortschritt', 'hat', 'die', 'Europäische', 'Kommission', 'daher', 'eine', 'Initiative', 'gestartet', ',', 'die', 'Wissenschaft', 'und', 'Gesellschaft', 'wieder', 'näher', 'zusammen', '##rücken', 'lassen', 'sollen', '.', 'Feder', '##führend', 'dabei', 'ist', 'ein', 'Konzept', ',', 'das', 'Res', '##pon', '##s', '##ible', 'Research', 'and', 'Innovation', '(', 'R', '##R']\n",
      " \toffsets: [0, 4, 12, 16, 22, 24, 35, 39, 49, 52, 54, 55, 63, 67, 72, 86, 89, 93, 105, 107, 112, 114, 117, 128, 132, 145, 149, 162, 168, 173, 178, 184, 193, 196, 202, 204, 209, 215, 219, 222, 228, 232, 237, 246, 256, 260, 262, 266, 270, 283, 286, 290, 296, 300, 302, 315, 322, 332, 336, 340, 347, 353, 362, 374, 380, 394, 396, 400, 410, 415, 418, 428, 432, 444, 448, 455, 457, 468, 472, 480, 494, 498, 504, 509, 515, 519, 531, 538, 550, 554, 558, 570, 581, 587, 592, 603, 612, 614, 618, 631, 635, 648, 655, 661, 669, 676, 683, 689, 691, 696, 704, 710, 714, 718, 725, 727, 731, 734, 737, 738, 743, 752, 756, 767, 768, 769]\n",
      " \tstart_of_word: [True, True, True, True, False, True, True, True, True, True, False, False, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, False, True, False, False, True, False, True, False, True, True, True, False, True, True, False, False, True, True, True, True, True, False, False, True, True, True, True, True, True, True, False, True, True, True, False, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, False, True, True, True, False, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, False, True, True, False, True, False, True, True, True, True, False, True, True, False, False, False, True, True, True, True, False, False]\n",
      "Features: \n",
      " \tinput_ids: [3, 295, 4483, 142, 2091, 26897, 25382, 127, 4471, 104, 1470, 243, 3596, 142, 380, 7431, 50, 21, 3497, 4813, 2319, 243, 346, 2898, 88, 3497, 42, 2183, 2026, 144, 155, 4734, 8632, 147, 11147, 5982, 7482, 5958, 4877, 7, 261, 30, 2719, 3873, 7231, 19204, 8716, 791, 21, 3497, 50, 30, 1427, 2190, 2036, 7933, 266, 6764, 42, 30, 4853, 11318, 3471, 19534, 922, 24583, 26900, 42, 18868, 144, 181, 7231, 128, 8369, 21, 2787, 4813, 10063, 21, 7156, 8922, 21, 1427, 2190, 261, 86, 3848, 248, 18342, 193, 30, 8450, 4364, 1913, 155, 8975, 16072, 2036, 30, 3497, 42, 2183, 525, 4766, 1037, 8409, 1641, 1922, 4813, 7889, 24387, 1340, 127, 39, 3180, 2036, 93, 2813, 2969, 26902, 16067, 14783, 2755, 25382, 123, 76, 26938, 4]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tlabel_ids: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/24/2019 14:40:52 - INFO - farm.data_handler.processor -   *** Example ***\n",
      "ID: train-373-0\n",
      "Clear Text: \n",
      " \tlabel: Panorama\n",
      " \ttext: Innenministerium macht erneut von Durchgriffsrecht Gebrauch – Umsetzung \"so rasch wie möglich\". Villach – In der Hensel-Kaserne in Villach wird in den kommenden Wochen ein Containerdorf für 450 Asylwerber entstehen. Das Innenministerium macht vom Durchgriffsrecht Gebrauch, Land und Stadt sind am Freitag informiert worden, sagte Ministeriumssprecher Karl-Heinz Grundböck auf Anfrage der APA. Aufbau und Belegung sollen so rasch wie möglich vonstattengehen. Es gibt schon länger das Angebot des Verteidigungsministeriums, erläuterte Grundböck. Jetzt werde das betroffene Gelände per Verordnung zur Bundesbetreuungsstelle erklärt. Ein Verwaltungsübereinkommen mit dem Verteidigungsministerium liege bereits vor. Als nächstes werde der Bescheid erstellt. Weiters gehe es an die Planung zur Errichtung des Containerdorfs auf einem Freigelände der Kaserne. Die Villacher SPÖ hat bereits eine Protestveranstaltung angekündigt. Auf die Frage, warum das Innenministerium auffallend oft in Kärnten vom Durchgriffsrecht Gebrauch mache, meinte der Ministeriumssprecher, dass Kärnten seine Quote nicht erfülle. Nur dank des Durchgriffsrechts liegt Kärnten bei der Erfüllung der Quote auf Rang vier bzw. bei 98 Prozent. Über das Durchgriffsrecht sind in Kärnten über 1.000 Plätze geschaffen worden. Außerdem habe das Innenministerium keinen Einfluss darauf, welche Kasernen das Verteidigungsministerium anbiete. Für die Türk-Kaserne in Spittal, die ebenfalls als Bundesbetreuungsstelle im Gespräch ist, gibt es noch keine endgültige Entscheidung. Grundböck: Bei Spittal sind wir noch nicht in dieser Phase der Umsetzung.\n",
      "Tokenized: \n",
      " \t tokens: ['Innenminister', '##ium', 'macht', 'erneut', 'von', 'Durch', '##griff', '##s', '##recht', 'Gebrauch', '[UNK]', 'Umsetzung', '\"', 'so', 'rasch', 'wie', 'möglich', '\"', '.', 'Villa', '##ch', '[UNK]', 'In', 'der', 'Hen', '##sel', '-', 'Kas', '##erne', 'in', 'Villa', '##ch', 'wird', 'in', 'den', 'kommenden', 'Wochen', 'ein', 'Container', '##dorf', 'für', '450', 'Asyl', '##werber', 'entstehen', '.', 'Das', 'Innenminister', '##ium', 'macht', 'vom', 'Durch', '##griff', '##s', '##recht', 'Gebrauch', ',', 'Land', 'und', 'Stadt', 'sind', 'am', 'Freitag', 'informiert', 'worden', ',', 'sagte', 'Ministeriums', '##sprecher', 'Karl', '-', 'Heinz', 'Grund', '##bö', '##ck', 'auf', 'Anfrage', 'der', 'AP', '##A', '.', 'Aufbau', 'und', 'Beleg', '##ung', 'sollen', 'so', 'rasch', 'wie', 'möglich', 'von', '##statt', '##eng', '##ehen', '.', 'Es', 'gibt', 'schon', 'länger', 'das', 'Angebot', 'des', 'Verteidigungs', '##ministeriums', ',', 'erläuterte', 'Grund', '##bö', '##ck', '.', 'Jetzt', 'werde', 'das', 'betroffene', 'Gelände', 'per', 'Verordnung', 'zur', 'Bundes', '##betreuung', '##sst', '##elle', 'erklärt', '.', 'Ein', 'Verwaltungs']\n",
      " \toffsets: [0, 13, 17, 23, 30, 34, 39, 44, 45, 51, 60, 62, 72, 73, 76, 82, 86, 93, 94, 96, 101, 104, 106, 109, 113, 116, 119, 120, 123, 128, 131, 136, 139, 144, 147, 151, 161, 168, 172, 181, 186, 190, 194, 198, 205, 214, 216, 220, 233, 237, 243, 247, 252, 257, 258, 264, 272, 274, 279, 283, 289, 294, 297, 305, 316, 322, 324, 330, 342, 351, 355, 356, 362, 367, 369, 372, 376, 384, 388, 390, 391, 393, 400, 404, 409, 413, 420, 423, 429, 433, 441, 444, 449, 452, 456, 458, 461, 466, 472, 479, 483, 491, 495, 508, 520, 522, 533, 538, 540, 542, 544, 550, 556, 560, 571, 579, 583, 594, 598, 604, 613, 616, 621, 628, 630, 634]\n",
      " \tstart_of_word: [True, False, True, True, True, True, False, False, False, True, True, True, True, False, True, True, True, False, False, True, False, True, True, True, True, False, False, False, False, True, True, False, True, True, True, True, True, True, True, False, True, True, True, False, True, False, True, True, False, True, True, True, False, False, False, True, False, True, True, True, True, True, True, True, True, False, True, True, False, True, False, False, True, False, False, True, True, True, True, False, False, True, True, True, False, True, True, True, True, True, True, False, False, False, False, True, True, True, True, True, True, True, True, False, False, True, True, False, False, False, True, True, True, True, True, True, True, True, True, False, False, False, True, False, True, True]\n",
      "Features: \n",
      " \tinput_ids: [3, 13189, 660, 2241, 2815, 88, 1116, 1308, 26902, 652, 7205, 2, 8205, 151, 181, 11190, 246, 1465, 151, 4813, 9114, 8, 2, 173, 21, 4068, 618, 243, 6268, 13856, 50, 9114, 8, 292, 50, 86, 5649, 2124, 39, 16165, 2237, 142, 17257, 4033, 4151, 5066, 4813, 295, 13189, 660, 2241, 275, 1116, 1308, 26902, 652, 7205, 2036, 414, 42, 560, 287, 235, 4156, 10867, 671, 2036, 1267, 19016, 8397, 2888, 243, 10283, 565, 13802, 110, 115, 14303, 21, 19013, 26924, 4813, 7195, 42, 11992, 27, 1922, 181, 11190, 246, 1465, 88, 4443, 23324, 840, 4813, 482, 893, 764, 3530, 93, 4593, 91, 8693, 8948, 2036, 26641, 565, 13802, 110, 4813, 5072, 1631, 93, 22575, 5676, 3039, 4688, 252, 578, 20372, 1249, 1159, 3058, 4813, 198, 1494, 4]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tlabel_ids: 3\n",
      "07/24/2019 14:40:52 - INFO - farm.data_handler.processor -   *** Example ***\n",
      "ID: train-3933-0\n",
      "Clear Text: \n",
      " \tlabel: Inland\n",
      " \ttext: Warum die Fachhochschulen keine Koordinierungsstelle in Flüchtlingsfragen brauchen und was gegen Polarisierung hilft, erklärt Kurt Koleznik, Generalsekretär der Fachhochschulkonferenz. STANDARD: Welche Rolle nehmen die Fachhochschulen in der Flüchtlings- und Integrationshilfe wahr? Koleznik: Helfen, wo es geht. Die Hochschulen wissen, dass sie Teil der Zivilgesellschaft sind, und so bringen sie sich auch ein – vom Studentenheim, das zur Verfügung gestellt wird, über Deutschkurse bis zu Spenden. Mitarbeiter haben Anspruch auf Extraurlaub, wenn sie karitativ tätig sind. Oft ist es das Engagement Einzelner, etwa wenn verschiedene Veranstaltungen für minderjährige unbegleitete Flüchtlinge ins Leben gerufen werden. STANDARD: Die Universitäten haben das koordinierende Projekt more im Ausbau – brauchen die Fachhochschulen keine solche Koordinierungsstelle? Koleznik: Wir haben das überlegt, sind aber zum Schluss gekommen, dass die FHs vor Ort wirken und sich den Bedürfnissen entsprechend in ihren Regionen mit Initiativen und Vereinen koordinieren. So kann geschehen, was jeweils gebraucht wird. STANDARD: Wie sieht es denn mit der Zulassung zum Studium aus, sind besondere Programme für Asylwerber geplant? Koleznik: Grundsätzlich reicht es nicht, nur Flüchtling zu sein. Aufnahmetests müssen sein. Allerdings haben wir da gewissen Spielraum, etwa wenn jemand die Hochschulreife behauptet, aber keine Zeugnisse vorweisen kann, dann bieten sich Feststellungsprüfungen an – oft sind die Hochschulen, an denen die Flüchtlinge zuvor eingeschrieben waren, ja auch bekannt. Dennoch ist das zu überprüfen – das gilt auch für Nostrifizierungen. Die Standards sind zu halten. Aber es besteht die Möglichkeit, etwa Gruppen bei den Aufnahmetests zu bilden, weil es etwa nicht immer günstig ist, AHS-Absolventen mit Asylberechtigten in einer Gruppe zu testen. Wobei da auch nützlich ist, dass wir insgesamt 46 Studiengänge in Englisch anbieten. STANDARD: Besteht vonseiten Asylberechtigter derzeit viel Interesse daran, in eine heimische FH zu kommen? Koleznik: Bis jetzt ist die Nachfrage sehr gering. Das kann sich aber ändern, wir starten die neuen Aufnahmetests im Frühjahr. Ich erwarte Interesse mit gewisser Zeitverzögerung – es spielt ja so vieles mit, die Leute müssen auch erst einmal ankommen, würdig wohnen können, die Kriegstraumata bearbeiten. STANDARD: Die Rolle der Fachhochschulkonferenz? Koleznik: Wir sind für die rechtliche Beratung da – für alles, was Anrechnungen und Nostrifizierungen betrifft oder Stipendienmöglichkeiten. STANDARD: Zu den Profilen im tertiären Sektor: Gibt es Neuigkeiten aus den intersektoralen Arbeitsgruppen? Es sollten ja die Universitäten entlastet werden. Koleznik: Dieser Prozess beginnt im neuen Jahr, wir hatten diese Diskussion eingefordert, jetzt beschäftigt sich die Hochschulkonferenz damit. Es geht im Kern darum, die berufsfeldbezogenen Studien zu den FHs zu verlagern. STANDARD: Wie etwa Jus? Koleznik: Ja, oder Maschinenbau, nichtärztliche Gesundheitsberufe, die Elementarpädagogik. Da wäre viel drinnen für die Fachhochschulen und damit gleichzeitig für die Profilschärfung Universitäten/FHs. STANDARD: Was kann gegen Polarisierung und gegen das Ausnützen und Schüren von Ängsten in der Migrationsdebatte getan werden? Koleznik: Die Wahrheit ist zumutbar. Jedem. Politiker sollen Karten auf den Tisch legen und Klartext reden. STANDARD: Aber Angst lässt sich nicht mit Zahlen und Argumenten auflösen. Koleznik: Oh doch, mit Offenheit und Glaubwürdigkeit – natürlich nicht mit Argumenten, die mit einem Rucksack voll hidden agenda daherkommen.\n",
      "Tokenized: \n",
      " \t tokens: ['Warum', 'die', 'Fachhochschule', '##n', 'keine', 'Koordin', '##ierungs', '##stelle', 'in', 'Flüchtlings', '##fragen', 'brauchen', 'und', 'was', 'gegen', 'Polar', '##isierung', 'hilft', ',', 'erklärt', 'Kurt', 'Kol', '##e', '##z', '##nik', ',', 'Generalsekretär', 'der', 'Fach', '##hoch', '##schul', '##konferenz', '.', 'S', '##TA', '##N', '##DA', '##R', '##D', ':', 'Welche', 'Rolle', 'nehmen', 'die', 'Fachhochschule', '##n', 'in', 'der', 'Flüchtlings', '-', 'und', 'Integrations', '##hilfe', 'wahr', '[UNK]', 'Kol', '##e', '##z', '##nik', ':', 'Hel', '##fen', ',', 'wo', 'es', 'geht', '.', 'Die', 'Hochschulen', 'wissen', ',', 'dass', 'sie', 'Teil', 'der', 'Zivil', '##gesellschaft', 'sind', ',', 'und', 'so', 'bringen', 'sie', 'sich', 'auch', 'ein', '[UNK]', 'vom', 'Studenten', '##heim', ',', 'das', 'zur', 'Verfügung', 'gestellt', 'wird', ',', 'über', 'Deutsch', '##kurse', 'bis', 'zu', 'Spenden', '.', 'Mitarbeiter', 'haben', 'Anspruch', 'auf', 'Extra', '##urlaub', ',', 'wenn', 'sie', 'kar', '##itat', '##iv', 'tätig', 'sind', '.', 'Oft', 'ist', 'es', 'das', 'Engagement', 'Einzelne', '##r']\n",
      " \toffsets: [0, 6, 10, 24, 26, 32, 39, 46, 53, 56, 67, 74, 83, 87, 91, 97, 102, 111, 116, 118, 126, 131, 134, 135, 136, 139, 141, 157, 161, 165, 169, 174, 183, 185, 186, 188, 189, 191, 192, 193, 195, 202, 208, 215, 219, 233, 235, 238, 242, 253, 255, 259, 271, 277, 281, 283, 286, 287, 288, 291, 293, 296, 299, 301, 304, 307, 311, 313, 317, 329, 335, 337, 342, 346, 351, 355, 360, 373, 377, 379, 383, 386, 394, 398, 403, 408, 412, 414, 418, 427, 431, 433, 437, 441, 451, 460, 464, 466, 471, 478, 484, 488, 491, 498, 500, 512, 518, 527, 531, 536, 542, 544, 549, 553, 556, 560, 563, 569, 573, 575, 579, 583, 586, 590, 601, 609]\n",
      " \tstart_of_word: [True, True, True, False, True, True, False, False, True, True, False, True, True, True, True, True, False, True, False, True, True, True, False, False, False, False, True, True, True, False, False, False, False, True, False, False, False, False, False, False, True, True, True, True, True, False, True, True, True, False, True, True, False, True, False, True, False, False, False, False, True, False, False, True, True, True, False, True, True, True, False, True, True, True, True, True, False, True, False, True, True, True, True, True, True, True, True, True, True, False, False, True, True, True, True, True, False, True, True, False, True, True, True, False, True, True, True, True, True, False, False, True, True, True, False, False, True, True, False, True, True, True, True, True, True, False]\n",
      "Features: \n",
      " \tinput_ids: [3, 8357, 30, 23789, 26898, 668, 11945, 1737, 1947, 50, 9246, 5521, 10044, 42, 961, 383, 21939, 3873, 11486, 2036, 3058, 8877, 3666, 26897, 26916, 15358, 2036, 16247, 21, 2038, 5670, 1720, 9671, 4813, 24, 10080, 26947, 6291, 26938, 26926, 5982, 14576, 2560, 3513, 30, 23789, 26898, 50, 21, 9246, 243, 42, 20743, 2821, 2473, 2, 3666, 26897, 26916, 15358, 5982, 2684, 451, 2036, 743, 229, 1398, 4813, 125, 13724, 5029, 2036, 221, 213, 717, 21, 5645, 2907, 287, 2036, 42, 181, 4169, 213, 144, 194, 39, 2, 275, 5170, 1156, 2036, 93, 252, 3009, 3047, 292, 2036, 204, 497, 16894, 255, 81, 12558, 4813, 2153, 474, 1916, 115, 20250, 12822, 2036, 557, 213, 17078, 20630, 293, 2481, 287, 4813, 13157, 127, 229, 93, 9243, 23583, 26900, 4]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tlabel_ids: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/24/2019 14:40:52 - INFO - farm.data_handler.data_silo -   Loading dev set as a slice of train set\n",
      "07/24/2019 14:40:52 - INFO - farm.data_handler.data_silo -   Took 924 samples out of train set to create dev set (dev split = 0.1)\n",
      "07/24/2019 14:40:52 - INFO - farm.data_handler.data_silo -   Loading test set from: data/gnad/test.csv\n",
      "07/24/2019 14:41:12 - INFO - farm.data_handler.processor -   *** Show 3 random examples ***\n",
      "07/24/2019 14:41:12 - INFO - farm.data_handler.processor -   *** Example ***\n",
      "ID: test-789-0\n",
      "Clear Text: \n",
      " \tlabel: Sport\n",
      " \ttext: Red Bull Salzburg hat erst als drittes Team in der Geschichte das Double erfolgreich verteidigt. Die Salzburger holten sich am Mittwochabend mit einem 2:0-Sieg nach Verlängerung gegen die Wiener Austria im Klagenfurter Wörthersee-Stadion auch den Titel im ÖFB-Fußball-Cup. Zum Matchwinner für den Meister avancierten Jonatan Soriano (95.) und Felipe Pires (108.).\n",
      "Tokenized: \n",
      " \t tokens: ['Red', 'Bull', 'Salzburg', 'hat', 'erst', 'als', 'drittes', 'Team', 'in', 'der', 'Geschichte', 'das', 'Dou', '##ble', 'erfolgreich', 'verteidigt', '.', 'Die', 'Salzburger', 'holte', '##n', 'sich', 'am', 'Mittwochabend', 'mit', 'einem', '2', ':', '0', '-', 'Sieg', 'nach', 'Verlängerung', 'gegen', 'die', 'Wiener', 'Austria', 'im', 'Klagen', '##furter', 'Wör', '##ther', '##see', '-', 'Stadion', 'auch', 'den', 'Titel', 'im', 'Ö', '##FB', '-', 'Fußball', '-', 'Cup', '.', 'Zum', 'Match', '##win', '##ner', 'für', 'den', 'Meister', 'avancierte', '##n', 'Jon', '##ata', '##n', 'Sor', '##iano', '(', '95', '.', ')', 'und', 'Fel', '##ipe', 'Pir', '##es', '(', '108', '.', ')', '.']\n",
      " \toffsets: [0, 4, 9, 18, 22, 27, 31, 39, 44, 47, 51, 62, 66, 69, 73, 85, 95, 97, 101, 112, 117, 119, 124, 127, 141, 145, 151, 152, 153, 154, 155, 160, 165, 178, 184, 188, 195, 203, 206, 212, 219, 222, 226, 229, 230, 238, 243, 247, 253, 256, 257, 259, 260, 267, 268, 271, 273, 277, 282, 285, 289, 293, 297, 305, 315, 317, 320, 323, 325, 328, 333, 334, 336, 337, 339, 343, 346, 350, 353, 356, 357, 360, 361, 362]\n",
      " \tstart_of_word: [True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, False, True, True, True, False, True, True, True, True, True, True, False, False, False, False, True, True, True, True, True, True, True, True, False, True, False, False, False, False, True, True, True, True, True, False, False, False, False, False, False, True, True, False, False, True, True, True, True, False, True, False, False, True, False, True, False, False, False, True, True, False, True, False, True, False, False, False, False]\n",
      "Features: \n",
      " \tinput_ids: [3, 2799, 12378, 11054, 193, 624, 153, 24432, 2299, 50, 21, 2009, 93, 13351, 6180, 3321, 13951, 4813, 125, 19294, 10088, 26898, 144, 235, 25557, 114, 297, 99, 5982, 1131, 243, 4035, 188, 8793, 383, 30, 5596, 23760, 106, 13254, 20154, 21870, 9190, 3249, 243, 8374, 194, 86, 1836, 106, 1092, 7768, 243, 1820, 243, 7638, 4813, 2147, 19552, 4279, 344, 142, 86, 2318, 26213, 26898, 10224, 6046, 26898, 15283, 9412, 123, 12003, 4813, 5133, 42, 4243, 16640, 9417, 16, 123, 19746, 4813, 5133, 4813, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tlabel_ids: 1\n",
      "07/24/2019 14:41:12 - INFO - farm.data_handler.processor -   *** Example ***\n",
      "ID: test-853-0\n",
      "Clear Text: \n",
      " \tlabel: Web\n",
      " \ttext: Flash an der Vorderseite, eventuell Fingerabruck-Scanner – Kleiner Bezel und große Kamera. Die vor kurzem verschickte Einladung lässt wenig Zweifel: In wenigen Tagen wird Motorola seine neue Smartphone-Generation vorstellen. Neben dem kostengünstigen Moto G soll es auch ein neues Moto X geben – und von diesem sind nun vorab erste Fotos aufgetaucht. Aus diesen lassen sich einige Details schließen: So ist ein LED-Flash an der Vorderseite zu erkennen, der Selfie-Fokus der Smartphone-Hersteller erreicht also einen neuen Höhepunkt. Das neue Moto X soll zudem endlich Stereo-Lautsprecher haben, wobei der untere gleichzeitig als Fingerabdruck-Scanner fungieren soll. Este es el nuevo Moto X y datos casi confirmados del nuevo moto g.Primero vemos al moto X, mágenes del equipo real y no... Die grundlegende Design-Richtung behält Motorola offenbar bei, die Rückseite ist also weiterhin gebogen. Neu ist allerdings ein Balken auf der Rückseite, der Kamera, Flash und Motorola-Logo umfasst. Auch fällt auf, dass der Bezel, also der Bereich zwischen Bildschirm- und Gehäuserand, deutlich kleiner als bei bisherigen Motorola-Smartphones ist. Zur Hardwareausstattung verrät der aktuelle Leak sonst wenig. Zuletzt war hier von einem Snapdragon 808-Prozessor sowie einem 5,2-Zoll-Bildschirm mit QHD-Auflösung zu hören. Neu ist allerdings der Hinweis, das das Moto X (2015) angeblich eine Kamera mit 21 Megapixel aufweisen soll.\n",
      "Tokenized: \n",
      " \t tokens: ['Fla', '##sh', 'an', 'der', 'Vorder', '##seite', ',', 'eventuell', 'Finger', '##abr', '##uck', '-', 'Sc', '##anner', '[UNK]', 'Kleine', '##r', 'Be', '##zel', 'und', 'große', 'Kamera', '.', 'Die', 'vor', 'kurzem', 'versch', '##ickte', 'Einladung', 'lässt', 'wenig', 'Zweifel', ':', 'In', 'wenigen', 'Tagen', 'wird', 'Motor', '##ola', 'seine', 'neue', 'Smartphone', '-', 'Generation', 'vorstellen', '.', 'Neben', 'dem', 'kosten', '##günst', '##igen', 'Mot', '##o', 'G', 'soll', 'es', 'auch', 'ein', 'neues', 'Mot', '##o', 'X', 'geben', '[UNK]', 'und', 'von', 'diesem', 'sind', 'nun', 'vorab', 'erste', 'Fotos', 'aufge', '##tau', '##cht', '.', 'Aus', 'diesen', 'lassen', 'sich', 'einige', 'Details', 'schließen', ':', 'So', 'ist', 'ein', 'L', '##ED', '-', 'Fla', '##sh', 'an', 'der', 'Vorder', '##seite', 'zu', 'erkennen', ',', 'der', 'Sel', '##fi', '##e', '-', 'Fokus', 'der', 'Smartphone', '-', 'Hersteller', 'erreicht', 'also', 'einen', 'neuen', 'Höhepunkt', '.', 'Das', 'neue', 'Mot', '##o', 'X', 'soll', 'zudem', 'endlich', 'Ster', '##eo', '-']\n",
      " \toffsets: [0, 3, 6, 9, 13, 19, 24, 26, 36, 42, 45, 48, 49, 51, 57, 59, 65, 67, 69, 73, 77, 83, 89, 91, 95, 99, 106, 112, 118, 128, 134, 140, 147, 149, 152, 160, 166, 171, 176, 180, 186, 191, 201, 202, 213, 223, 225, 231, 235, 241, 246, 251, 254, 256, 258, 263, 266, 271, 275, 281, 284, 286, 288, 294, 296, 300, 304, 311, 316, 320, 326, 332, 338, 343, 346, 349, 351, 355, 362, 369, 374, 381, 389, 398, 400, 403, 407, 411, 412, 414, 415, 418, 421, 424, 428, 434, 440, 443, 451, 453, 457, 460, 462, 463, 464, 470, 474, 484, 485, 496, 505, 510, 516, 522, 531, 533, 537, 542, 545, 547, 549, 554, 560, 568, 572, 574]\n",
      " \tstart_of_word: [True, False, True, True, True, False, False, True, True, False, False, False, False, False, True, True, False, True, False, True, True, True, False, True, True, True, True, False, True, True, True, True, False, True, True, True, True, True, False, True, True, True, False, False, True, False, True, True, True, False, False, True, False, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, True, True, True, True, True, True, True, False, True, True, True, True, False, False, False, False, True, True, True, False, True, True, False, True, True, False, False, False, False, True, True, False, False, True, True, True, True, True, False, True, True, True, False, True, True, True, True, True, False, False]\n",
      "Features: \n",
      " \tinput_ids: [3, 9862, 3653, 104, 21, 6957, 3337, 2036, 16799, 11380, 25757, 4155, 243, 3048, 23810, 2, 15922, 26900, 163, 842, 42, 1856, 8967, 4813, 125, 200, 15889, 2027, 12295, 16542, 2026, 2210, 5003, 5982, 173, 5279, 3499, 292, 4147, 4529, 498, 1234, 18822, 243, 8454, 13012, 4813, 1687, 128, 5482, 14295, 219, 2225, 26910, 61, 459, 229, 194, 39, 5083, 2225, 26910, 1899, 2938, 2, 42, 88, 798, 287, 1113, 19165, 1139, 9011, 1239, 13248, 191, 4813, 291, 1377, 1641, 144, 1967, 10834, 7393, 5982, 507, 127, 39, 94, 10598, 243, 9862, 3653, 104, 21, 6957, 3337, 81, 4536, 2036, 21, 8169, 19303, 26897, 243, 17360, 21, 18822, 243, 6928, 3176, 1638, 303, 1280, 10700, 4813, 295, 1234, 2225, 26910, 1899, 459, 2491, 7528, 5907, 21331, 243, 4]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tlabel_ids: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/24/2019 14:41:12 - INFO - farm.data_handler.processor -   *** Example ***\n",
      "ID: test-788-0\n",
      "Clear Text: \n",
      " \tlabel: Wirtschaft\n",
      " \ttext: Zwei Ex-Mitarbeiter der Wirtschaftsprüfungs- und Steuerberatungsgesellschaft PricewaterhouseCoopers kommen wie ein Journalist vor Gericht. Luxemburg – In der Luxleaks-Affäre um Steuervorteile für internationale Konzerne in Luxemburg wird den Informanten der Prozess gemacht. Drei Männer müssen sich vom 26. April an vor einem Gericht in Luxemburg-Stadt verantworten, weil sie die Steuerdeals zwischen Unternehmen und Steuerbehörden an die Öffentlichkeit brachten. Das teilte ein Justizsprecher am Freitag in Luxemburg mit. Angeklagt sind zwei Ex-Mitarbeiter der Wirtschaftsprüfungs- und Steuerberatungsgesellschaft PricewaterhouseCoopers (PwC) sowie ein französischer Journalist. Die früheren PwC-Angestellten werden des Diebstahls, des illegalen Zugriffs auf ein Computersystem, der Weitergabe von Geschäftsgeheimnissen, des Bruchs der beruflichen Schweigepflicht und des Besitzes gestohlener Dokumente beschuldigt. Der Journalist ist angeklagt, unterschlagene Dokumente veröffentlicht zu haben. Für den Prozess sind fünf Verhandlungstage bis zum 4. Mai angesetzt. Die Luxleaks genannten Veröffentlichungen lösten eine europaweite Diskussion über Steuertricksereien aus. Die luxemburgischen Finanzbehörden hatten über Jahre hinweg mit einer Reihe Großkonzerne individuelle Vereinbarungen über die zu zahlenden Steuern geschlossen. Die luxemburgische Regierung hatte ebenso wie PwC und die Unternehmen erklärt, diese Steuerfestsetzungen (Tax Rulings) entsprächen den geltenden Gesetzen.\n",
      "Tokenized: \n",
      " \t tokens: ['Zwei', 'Ex', '-', 'Mitarbeiter', 'der', 'Wirtschafts', '##prüfung', '##s', '-', 'und', 'Steuer', '##beratung', '##s', '##gesellschaft', 'Pri', '##ce', '##wa', '##ter', '##house', '##Co', '##oper', '##s', 'kommen', 'wie', 'ein', 'Journalist', 'vor', 'Gericht', '.', 'Luxemburg', '[UNK]', 'In', 'der', 'Lux', '##le', '##aks', '-', 'Affäre', 'um', 'Steuer', '##vorteil', '##e', 'für', 'internationale', 'Konzerne', 'in', 'Luxemburg', 'wird', 'den', 'Inform', '##anten', 'der', 'Prozess', 'gemacht', '.', 'Drei', 'Männer', 'müssen', 'sich', 'vom', '26', '.', 'April', 'an', 'vor', 'einem', 'Gericht', 'in', 'Luxemburg', '-', 'Stadt', 'verantworten', ',', 'weil', 'sie', 'die', 'Steuer', '##de', '##als', 'zwischen', 'Unternehmen', 'und', 'Steuer', '##behörden', 'an', 'die', 'Öffentlichkeit', 'brachten', '.', 'Das', 'teilte', 'ein', 'Justiz', '##sprecher', 'am', 'Freitag', 'in', 'Luxemburg', 'mit', '.', 'Angeklag', '##t', 'sind', 'zwei', 'Ex', '-', 'Mitarbeiter', 'der', 'Wirtschafts', '##prüfung', '##s', '-', 'und', 'Steuer', '##beratung', '##s', '##gesellschaft', 'Pri', '##ce', '##wa', '##ter', '##house', '##Co', '##oper', '##s', '(']\n",
      " \toffsets: [0, 5, 7, 8, 20, 24, 35, 42, 43, 45, 49, 55, 63, 64, 77, 80, 82, 84, 87, 92, 94, 98, 100, 107, 111, 115, 126, 130, 137, 139, 149, 151, 154, 158, 161, 163, 166, 167, 174, 177, 183, 190, 192, 196, 211, 220, 223, 233, 238, 242, 248, 254, 258, 266, 273, 275, 280, 287, 294, 299, 303, 305, 307, 313, 316, 320, 326, 334, 337, 346, 347, 353, 365, 367, 372, 376, 380, 386, 388, 392, 401, 413, 417, 423, 432, 435, 439, 454, 462, 464, 468, 475, 479, 485, 494, 497, 505, 508, 518, 521, 523, 531, 533, 538, 543, 545, 546, 558, 562, 573, 580, 581, 583, 587, 593, 601, 602, 615, 618, 620, 622, 625, 630, 632, 636, 638]\n",
      " \tstart_of_word: [True, True, False, False, True, True, False, False, False, True, True, False, False, False, True, False, False, False, False, False, False, False, True, True, True, True, True, True, False, True, True, True, True, True, False, False, False, False, True, True, False, False, True, True, True, True, True, True, True, True, False, True, True, True, False, True, True, True, True, True, True, False, True, True, True, True, True, True, True, False, False, True, False, True, True, True, True, False, False, True, True, True, True, False, True, True, True, True, False, True, True, True, True, False, True, True, True, True, True, False, True, False, True, True, True, False, False, True, True, False, False, False, True, True, False, False, False, True, False, False, False, False, False, False, False, True]\n",
      "Features: \n",
      " \tinput_ids: [3, 1153, 1108, 243, 2153, 21, 2810, 4505, 26902, 243, 42, 1951, 15100, 26902, 2907, 4633, 950, 427, 60, 17676, 10507, 4010, 26902, 1561, 246, 39, 10486, 200, 1291, 4813, 12419, 2, 173, 21, 6282, 134, 13216, 243, 17501, 259, 1951, 24219, 26897, 142, 6296, 23459, 50, 12419, 292, 86, 2486, 2441, 21, 2882, 2119, 4813, 2955, 3284, 1475, 144, 275, 1636, 4813, 1331, 104, 200, 297, 1291, 50, 12419, 243, 560, 24958, 2036, 982, 213, 30, 1951, 57, 837, 597, 1189, 42, 1951, 9517, 104, 30, 5610, 12796, 4813, 295, 5751, 39, 5671, 8397, 235, 4156, 50, 12419, 114, 4813, 3746, 26901, 287, 382, 1108, 243, 2153, 21, 2810, 4505, 26902, 243, 42, 1951, 15100, 26902, 2907, 4633, 950, 427, 60, 17676, 10507, 4010, 26902, 123, 4]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tlabel_ids: 5\n",
      "07/24/2019 14:41:12 - INFO - farm.data_handler.data_silo -   Examples in train: 8320\n",
      "07/24/2019 14:41:12 - INFO - farm.data_handler.data_silo -   Examples in dev  : 924\n",
      "07/24/2019 14:41:12 - INFO - farm.data_handler.data_silo -   Examples in test : 1027\n",
      "07/24/2019 14:41:12 - INFO - farm.data_handler.data_silo -   Using class weights: [0.6723232323232323, 0.9540190345143905, 0.7646356033452808, 0.6728125505418082, 2.0362212432697016, 0.8045643554781936, 2.154882154882155, 1.693121693121693, 1.134287661895024]\n"
     ]
    }
   ],
   "source": [
    "# We need a DataSilo in order to keep our train, dev and test sets separate.\n",
    "# The DataSilo will call the functions in the Processor to generate these sets.\n",
    "# From the DataSilo, we can fetch a PyTorch DataLoader object which will\n",
    "# be passed on to the model.\n",
    "# Here is a good place to define a batch size for the model\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "data_silo = DataSilo(\n",
    "    processor=processor,\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In FARM, we make a strong distinction between the language model and prediction head so that you can mix and match different building blocks for your needs.\n",
    "\n",
    "For example, in the transfer learning paradigm, you might have the one language model that you will be using for both document classification and NER. Or you perhaps you have a pretrained language model which you would like to adapt to your domain, then use for a downstream task such as question answering. \n",
    "\n",
    "All this is possible within FARM and requires only the replacement of a few modular components, as we shall see below.\n",
    "\n",
    "Let's first have a look at how we might set up a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The language model is the foundation on which modern NLP systems are built.\n",
    "# They encapsulate a general understanding of sentence semantics\n",
    "# and are not specific to any one task.\n",
    "\n",
    "# Here we are using Google's BERT model as implemented by HuggingFace. \n",
    "# The model being loaded is a German model that we trained. \n",
    "# You can also change the MODEL_NAME_OR_PATH to point to a BERT model that you\n",
    "# have saved or download one connected to the HuggingFace repository.\n",
    "# See farm.modeling.language_model.PRETRAINED_MODEL_ARCHIVE_MAP for a list of\n",
    "# available models\n",
    "\n",
    "MODEL_NAME_OR_PATH = \"bert-base-german-cased\"\n",
    "\n",
    "language_model = Bert.load(MODEL_NAME_OR_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A prediction head is a model that processes the output of the language model\n",
    "# for a specific task.\n",
    "# Prediction heads will look different depending on whether you're doing text classification\n",
    "# Named Entity Recognition (NER), question answering or some other task.\n",
    "# They should generate logits over the available prediction classes and contain methods\n",
    "# to convert these logits to losses or predictions \n",
    "\n",
    "# Here we use TextClassificationHead which receives a single fixed length sentence vector\n",
    "# and processes it using a feed forward neural network. layer_dims is a list of dimensions:\n",
    "# [input_dims, hidden_1_dims, hidden_2_dims ..., output_dims]\n",
    "\n",
    "# Here by default we have a single layer network.\n",
    "# It takes in a vector of length 768 (the default size of BERT's output).\n",
    "# It outputs a vector of length 9 (the number of classes in the GNAD dataset)\n",
    "\n",
    "LAYER_DIMS = [768, 9]\n",
    "\n",
    "prediction_head = TextClassificationHead(layer_dims=LAYER_DIMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The language model and prediction head are coupled together in the Adaptive Model.\n",
    "# This class takes care of model saving and loading and also coordinates\n",
    "# cases where there is more than one prediction head.\n",
    "\n",
    "# EMBEDS_DROPOUT_PROB is the probability that an element of the output vector from the\n",
    "# language model will be set to zero.\n",
    "EMBEDS_DROPOUT_PROB = 0.1\n",
    "\n",
    "model = AdaptiveModel(\n",
    "    language_model=language_model,\n",
    "    prediction_heads=[prediction_head],\n",
    "    embeds_dropout_prob=EMBEDS_DROPOUT_PROB,\n",
    "    lm_output_types=[\"per_sequence\"],\n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we initialize a Bert Adam optimizer that has a linear warmup and warmdown\n",
    "# Here you can set learning rate, the warmup proportion and number of epochs to train for\n",
    "\n",
    "LEARNING_RATE = 2e-5\n",
    "WARMUP_PROPORTION = 0.1\n",
    "N_EPOCHS = 1\n",
    "\n",
    "optimizer, warmup_linear = initialize_optimizer(\n",
    "    model=model,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    warmup_proportion=WARMUP_PROPORTION,\n",
    "    n_examples=data_silo.n_samples(\"train\"),\n",
    "    batch_size=data_silo.batch_size,\n",
    "    n_epochs=N_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop handled by this\n",
    "# It will also trigger evaluation during training using the dev data\n",
    "# and after training using the test data.\n",
    "\n",
    "# Set N_GPU to a positive value if CUDA is available\n",
    "N_GPU = 0\n",
    "\n",
    "trainer = Trainer(\n",
    "    optimizer=optimizer,\n",
    "    data_silo=data_silo,\n",
    "    epochs=N_EPOCHS,\n",
    "    n_gpu=N_GPU,\n",
    "    warmup_linear=warmup_linear,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trainer.train(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Switch to NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a transfer learning paradigm, there is a core computation that is shared amongst all tasks. FARM's modular structure means that you can easily swap out different building blocks to make the same language model work for many different tasks.\n",
    "\n",
    "We can adapt the above text classification model to NER by simply switching out the processor and prediction head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the new building blocks\n",
    "\n",
    "from farm.data_handler.processor import CONLLProcessor\n",
    "from farm.modeling.prediction_head import TokenClassificationHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This processor will preprocess the data for the CoNLL03 NER task\n",
    "\n",
    "ner_processor = CONLLProcessor(tokenizer=tokenizer,\n",
    "                               max_seq_len=128,\n",
    "                               data_dir=\"data/conll03de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This prediction head is also a feed forward neural network but expects one\n",
    "# vector per token in the input sequence and will generate a set of logits\n",
    "# for each input\n",
    "\n",
    "LAYER_DIMS = [768, 13]\n",
    "\n",
    "ner_prediction_head = TokenClassificationHead(layer_dims=LAYER_DIMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can integrate these new pieces with the rest using this code\n",
    "# It is pretty much the same structure as what we had above for text classification\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EMBEDS_DROPOUT_PROB = 0.1\n",
    "LEARNING_RATE = 2e-5\n",
    "WARMUP_PROPORTION = 0.1\n",
    "N_EPOCHS = 1\n",
    "N_GPU = 0\n",
    "\n",
    "data_silo = DataSilo(\n",
    "    processor=ner_processor,\n",
    "    batch_size=BATCH_SIZE)\n",
    "\n",
    "model = AdaptiveModel(\n",
    "    language_model=language_model,\n",
    "    prediction_heads=[ner_prediction_head],\n",
    "    embeds_dropout_prob=EMBEDS_DROPOUT_PROB,\n",
    "    lm_output_types=[\"per_token\"],\n",
    "    device=device)\n",
    "\n",
    "optimizer, warmup_linear = initialize_optimizer(\n",
    "    model=model,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    warmup_proportion=WARMUP_PROPORTION,\n",
    "    n_examples=data_silo.n_samples(\"train\"),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    n_epochs=N_EPOCHS)\n",
    "\n",
    "trainer = Trainer(\n",
    "    optimizer=optimizer,\n",
    "    data_silo=data_silo,\n",
    "    epochs=N_EPOCHS,\n",
    "    n_gpu=N_GPU,\n",
    "    warmup_linear=warmup_linear,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trainer.train(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
